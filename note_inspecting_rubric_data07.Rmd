---
title: "Note to Inspect Rubric Data 7"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_notebook:
    toc: yes
    toc_float:
      collapsed: yes
    code_folding: hide
  html_document:
    toc: yes
    toc_float:
      collapsed: no
    df_print: paged
    code_folding: hide
    fig_height: 7
    fig_width: 7
---

```{r, echo=FALSE, include=FALSE}
#knitr::opts_chunk$set(message = FALSE, warning = FALSE)
library(tidyverse)
options(dplyr.summarise.inform=FALSE) 
library(readxl)
```

Objective
================================================================================
Data are mostly cleaned and organized; PLOs are largely matched for Standard 4
reporting; yet, there are several critically missing pieces. 1) Present the
outcomes for those which are present and 2) sort out the current situation and
follow up with faculty/staff for missing information (i.e. missing data,
assessments, and mappings).



Set up
================================================================================
Import Data
--------------------------------------------------------------------------------
Codes are externalized for reuse. As a reference, data frames are as follows:

- `mdf` or main data frame contains the rubric outcome data merged with the course/assessment information gathered from the survey. Data are cleaned up.
- `non` or non-rubric data frame is separated from the same data source as the
rubric information of `mdf`. It contains the instructor's assessments of
outcomes at course level. Data are cleaned up.
- `past` data frame contains the assessment outcome data from the past.
- `rowmap` data frame summarizes the mapping between PLOs and rubric rows.

```{r}
source('read.R')
source('munge.R')
```
Those scripts have been updated to use the *edited* version of the survey result
data. See Note 5 for details. Given that change, the Notebooks 1-5 are
completely outdated.


New Issues
--------------------------------------------------------------------------------
New things in this note:

- [x] Drop BUS 499 GW1 Spring 2020 Annotated Bibliography from data, while
adding the observed into non-rubric
- [x] Drop ECO 421 001 from data, while adding the observed into non-rubric
- [x] Drop HRM 400 001 from data, while adding the observed into non-rubric

```{r}
mdf.original <- mdf
mdf <- mdf %>%
  filter(!( (Section == "BUS 499 GW1" & Semester == "Spring 2020" &
               Assessment == "Annotated Bibliography") |
             Section == "ECO 421 001" | Section == "HRM 400 001"))
```

Then scraped data will be re-introduced in the following.


PLO Measures for Standard 4
================================================================================
Overview
--------------------------------------------------------------------------------
For Standard 4, we only need a rather small subset of the assessments available.
Produce the summary of outcomes in the context of historical changes.

- ACBSP requires 3-5 data points, so make sure to have sufficient numbers.
- ACBSP requires graphs with sample sizes.
- Nuventive requires numbers. Produce data tables along with the graphs.

Once Standard 4 is done, we can discuss weakness/shortcomings and
strength/improvements in our program, then look at other courses - including the
ones at an earlier stage of each program - to find *opportunities for
improvement* and *close the loop*. That is, we can get to **Standard 6**
analysis.


Summarize Outcomes
--------------------------------------------------------------------------------
For this academic year, we have assessments both with and without rubrics. In
the following, I summarize the rubric-based assessments - observed at individual
level - at `Section` level, then combine them with the non-rubric-based
assessments - observed at `Section` level. Then, the summarized data will be
aggregated to `Course` level.

The individual data has `r nrow(mdf)` rows, while there are `r
n_distinct(mdf$UserId)` distinctive students, `r n_distinct(mdf$RubricId)`
rubrics with `r n_distinct(mdf$Name)` rows for `r n_distinct(mdf$Course)`
courses. Implementations of those courses are distinguished by `r
n_distinct(mdf$Section)` `Sections` over three `Semester`.

The data pulled from D2L contains Rubric ID, but not associated with courses or
instructors. Such additional information is provided through the survey
collected. They are merged in the script above and issues like inconsistent
names and typos have been handled, resulting in `mdf` data frame. Meanwhile, the
survey also contains the information about non-rubric assessments. They are
cleaned and separated into `non` data frame.

The individual data are necessary for analyzing the grade distributions and possible correlations in various grades. However, Standard 4 only requires the aggregates.  Therefore, I will summarize the outcomes at the aggregation level of course and rubric row.

First, the individual-level data are aggregated to `Course`-`Section`-`Semester`-`Assessment`-`Name`(Rubric Row) level ("Section & Rubric Row" level). At this stage, each implementation is distinguishable. Instructor level analysis can be done. In the aggregation, proportions of students who met the goal are calculated.

Second, the Section & Rubric Row level data above is combined with the rubric data *scraped from the D2L directly*. There are some missing in the retrieved D2L data. As a temporary measure, student outcomes are collected from D2L course pages manually. The results are summarized at the rubric row levels; hence compatible with the aggregated data mentioned above.

The non-rubric assessments mentioned before are merged at this stage. However, unlike the scraped data, those non-rubric assessments do not have rows. (All the rows are labeled "No Rubric".) If both rubric and non-rubric assessments exist, they need to be distinguished (Use `Rubric` flag).

Third, the data are aggregated to the course level, erasing the distinction between sections. This level is used for student outcome assessment. The resulting data is distinguished at `Course`-`Assessment`-`Name`(Rubric Row).

```{r}
tbl1 <- mdf %>% filter(str_detect(Name, "Major|Minor", negate = TRUE)) %>%
  group_by(Course, Section, Semester, Assessment, Name, PLO) %>%
  summarise(Met.UND = mean(Met.UND.bin), Met.GRD = mean(Met.GRD.bin),
            n = n_distinct(UserId),
            Rubric = TRUE)
```
```{r}
miss <- read_excel("data/D2L Missing Data Retrievals.xlsx", "Scraped")
miss <- miss %>%
  select(-c(Unsatisfactory:Advanced)) %>% mutate(Met.UND = Met, Met.GRD = Met)
tbl2 <- bind_rows(tbl1, miss)
#tbl2 %>% filter(Course == "BUS 499", Assessment == "Annotated Bibliography")
```
```{r}
tbl3 <- tbl2 %>%
  bind_rows(non %>% transmute(Course, Section, Semester, Assessment,
                              Name = "No Rubric", PLO,
                              Met.UND = np/n, Met.GRD = Met.UND, n,
                              Rubric = FALSE))
```


```{r}
tbl4 <- tbl3 %>% 
  group_by(Course, Assessment, Name, PLO, Rubric) %>%
  summarise(Met.UND = weighted.mean(Met.UND, n, na.rm = TRUE),
            Met.GRD = weighted.mean(Met.GRD, n, na.rm = TRUE),
            n = sum(n, na.rm = TRUE), n.sec = n_distinct(Section),
            Rubric = TRUE) %>% 
  ungroup()
summary(tbl4)
```

Prepare New
--------------------------------------------------------------------------------
```{r}
get_outcome <- function(plotag, rrow, program, plo, grad = FALSE){
  # Extract assessment by PLO Tags and Rubric Row (pattern matching)
  # Returns NA if Rubric Row is NA.
  if(is.na(rrow)){return(tibble(n = NA, Program = program, Met = NA, PLO = plo))}
  x <- tbl4 %>% filter(PLO == plotag, str_detect(Name, rrow))
  if(nrow(x) == 0){
    warning("Criteria result in empty dataset.\n")
    return(NA)
    }
  out <- x %>% group_by(Rubric) %>% 
      summarize(Met.GRD = mean(Met.GRD), Met.UND = mean(Met.UND), n = min(n)) %>%
      mutate(Program = program, PLO = plo)
  if(grad){
    out %>% mutate(Met = Met.GRD)
  }
  else{
    out %>% mutate(Met = Met.UND)
  }
}
#get_outcome(plotag = "ACC 1", rrow = "NA", program = "Accounting", plo = 1)
#get_outcome(plotag = "ACC 1", rrow = "No Rubric", program = "Accounting", plo = 1)
```


Prepare
--------------------------------------------------------------------------------
```{r}
get_outcome <- function(plotag, rrow, program, plo, grad = FALSE){
  if(is.na(rrow)){return(tibble(n = NA, Program = program, Met = NA, PLO = plo))}
  if(grad){
    tbl4 %>% filter(PLO == plotag, str_detect(Name, rrow)) %>% ungroup() %>% 
      summarize(Met = mean(Met.GRD), n = min(n)) %>%
      mutate(Program = program, PLO = plo)
  }
  else{
    tbl4 %>% filter(PLO == plotag, str_detect(Name, rrow)) %>% ungroup() %>% 
      summarize(Met = mean(Met.UND), n = min(n)) %>%
      mutate(Program = program, PLO = plo)
  }
}
#get_outcome(plotag = "ACC 1", rrow = "NA",
#            program = "Accounting", plo = 5)
```

```{r}
keys.all <- read_csv("data/mapping_keys.csv", na = "NA")
knitr::kable(keys.all)
```

```{r}
keys.all %>% filter(Program == "MBA")
past %>% filter(Program == "MBA", `Assessment Type Orientation` == "Internal")
names(past)
```

It would be straight forward to add 2019 data with sufficient information,
rather than selecting relevant rows...?

```{r}
get_outcomes <- function(program, grad = FALSE){
  # Wrapper to return a combined results for each program
  keys <- keys.all %>% filter(Program == program)
  lres <- list()
  plotags <- keys$PLO.Tags
  rrows <- keys$Rubric.Rows
  for(i in 1:length(plotags)){
    lres[[i]] <- get_outcome(plotags[i], rrows[i], program, i, grad)
  }
  lres
}

merge_outcomes <- function(lres, program){
  # Wrapper function to merge with the historical assessment results
  keys <- keys.all %>% filter(Program == program)
  #lres <- lres[!is.na(lres)] # Missing assessment returns NA
  x <- bind_rows(lres)
  x <- x %>% ungroup() %>%
    transmute(`Learning Objective Number` = PLO,
              `Academic Year` = rep(2019, nrow(x)),
              `Outcome` = Met, `Sample Size` = n, `Outcome Goal` = keys$Goals)
  
  y <- past %>%
    filter(Program == program, `Assessment Type Orientation` == "Internal") %>% 
    select(`Learning Objective Number`, `Academic Year`,
           Outcome, `Sample Size`, `Outcome Goal`)
  out <- bind_rows(x, y)
  out %>% arrange(`Learning Objective Number`, `Academic Year`)
}

getmerge_outcomes <- function(program, grad = FALSE){
  lres <- get_outcomes(program, grad)
  merge_outcomes(lres, program)
}

#getmerge_outcomes("Accounting")
#past %>% filter(Program == "MBA", str_detect(`Assessment Type`, "(Internal$)|(Internal Formative)"))
```

```{r}
make_graph <- function(df.out, program){
  title <- paste0(program, ", Prevalence of Achievments Over Academic Years, by PLO")
  caption <- "Grey number represents sample size.\nFor 2019, minimum sample size is used if prevalence is computed from multiple criteria."
  ymin <- min(min(df.out$Outcome, na.rm = TRUE),
              min(df.out$`Outcome Goal` - 0.1, na.rm = TRUE))
  
  p <- ggplot(df.out, aes(x = `Academic Year`, y = Outcome,
                          group = `Learning Objective Number`)) +
    geom_line(na.rm = TRUE) +
    geom_point(aes(color = Outcome > `Outcome Goal`), na.rm = TRUE) +
    scale_colour_manual(values = setNames(c('blue','red'),c(T, F))) +
    geom_text(aes(`Academic Year`, 0.65, label = round(`Sample Size`, 0)),
              alpha = 0.4, na.rm = TRUE) +
    geom_hline(aes(yintercept = `Outcome Goal`), alpha = 0.4, color = "red") +
    scale_y_continuous(labels=scales::percent,
                       breaks = seq(0, 1, 0.2), limits = c(ymin, 1))
  p + facet_wrap(vars(`Learning Objective Number`)) +
    theme_minimal() +
    labs(title = title, caption = caption) +
    theme(axis.title = element_blank(),
          text = element_text(family = "serif"),
          panel.grid.minor.x = element_blank(),
          legend.position = "none")
}
```


Outcomes
================================================================================
Try
--------------------------------------------------------------------------------
```{r}
acc <- getmerge_outcomes("Accounting")
make_graph(acc, "Accounting")
bus <- getmerge_outcomes("Business Core")
make_graph(bus, "Business Core")
eco <- getmerge_outcomes("Economics")
make_graph(eco, "Economics")
hrm <- getmerge_outcomes("Human Resources Management")
make_graph(hrm, "Human Resources Management")
mgt <- getmerge_outcomes("Management")
make_graph(mgt, "Management")
mba <- getmerge_outcomes("MBA", grad = TRUE)
make_graph(mba, "MBA")
```


Next
================================================================================
