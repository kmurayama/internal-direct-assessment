---
title: "Note to Inspect Rubric Data 3"
output:
  html_notebook:
    toc: true
    toc_float:
      collapsed: false
    theme: paper
---


# Objective
Data are mostly cleaned and organized through examining each course. Bring back those procedures into the data munging stage and produce the base statistics for Standard 4.

# Set up

```{r, echo=FALSE, include=FALSE}
#knitr::opts_chunk$set(message = FALSE, warning = FALSE)
library(tidyverse)
library(readxl)
```

## Import D2L Rubric Outcomes
```{r import-d2l}
fn <- "data/Rubrics.xlsx"
df <- read_xlsx(fn) %>%
  mutate(across(c(RubricId:Name, LevelAchieved), factor),
         IsScoreOverridden = (IsScoreOverridden == "True"))
```

## Import Survey
As before, import the first 12 columns that are relevant to rubrics. Alter lengthy column names for convenience.
```{r import-survey}
fn <- "data/Tracking of Assessment of Student Learning Outcomes Data Collection.xlsx"
res <- read_excel(fn, sheet = "Response0602")
res <- res[res$`I graded this assessment using a rubric on D2L.` == "Yes", ]
res <- res[1:12]

qs <- names(res)
responder.info <- c("ID", "Started", "Completed", "Email", "Name")
course.info <- c("Semester", "Course")
assessment.info <- c("Assessment Name", "Rubric Usage")
rubric.info <- c("URL", "Intrepretation", "Action for Improvement")
names(res) <- c(responder.info, course.info, assessment.info, rubric.info)
```

## Clean Up Survey
Need to drop some error entries. One is Ed's entry later on. There are two early entries by Beth before we changed the survey questions. Neeley's entry has two rubrics, so need to split them.
```{r drop-entries}
res <- res[res$ID != 1 & res$ID != 2, ] # Drop early error entries

assess.name <- res[res$ID == 41, c("Assessment Name", "URL")] # Keep double entry 
anames <- str_split(assess.name$`Assessment Name`, ",", simplify = TRUE)
urls <- str_split(assess.name$URL, "Burts", simplify = TRUE)

x <- res[res$ID == 41, ]
x$ID <- nrow(res)
x[c("Assessment Name", "URL")] <- list(anames[2], urls[2])
res[res$ID == 41, c("Assessment Name", "URL")] <- list(anames[1], urls[1])
res[res$ID == 159, ] <- x # Replace Ed's entry with the modified Neeley's
```

Course names have some minor errors. It'll be easier if correcting them and split its components for later use.
```{r clean-course}
x <- res$Course
x <- str_replace(x, "GW[I|!]", "GW1") # Replace some typos
x <- str_replace(x, "GS1", "GW1") # Replace some typos
x <- str_remove(x, "[0-9]{4,}") # Remove leading time stamp
x <- str_replace(x, "BS[U]?", "BUS") # Replace less critical typo
x <- str_replace(x, "-01", "-001") # Replace less critical typo

cid1 <- str_match(x, "[A-Z]{2,3}") # Extract course program (e.g. BUS, MKT)
cid2 <- str_extract_all(x, "(CD|G[WS])?[0-9]{1,3}", simplify = TRUE) # Extract
res$Course <- paste(cid1, cid2[, 1]) # Then merge for course id e.g. MGT 300
res$Section <- paste(cid1, cid2[, 1], cid2[, 2]) # Likewise, e.g. MGT 300 001

```

Lastly, prepare for merge. Need to have unique IDs.
```{r extract-rubricid}
x <- str_extract_all(res$URL, "rubricId=[0-9]{6}", simplify=TRUE)
res$RubricId <- factor(str_extract_all(x, "[0-9]{6}", simplify=TRUE))
```
```{r, eval=FALSE}
tbl <- table(res$RubricId)
dups <- tbl[tbl > 1]
res[res$RubricId==names(dups)[1], ]
# Drop 2, 22
res[res$RubricId==names(dups)[2], ]
# Drop 41 (see the note)
res[res$RubricId==names(dups)[3], ]
# Drop 77 Why resubmit?
res[res$RubricId==names(dups)[4], ]
# Drop 71 ?
res[res$RubricId==names(dups)[5], ]
# Drop 1
res[res$RubricId==names(dups)[6], ]
# Drop 83 ?
res[res$RubricId==names(dups)[7], ]
# Drop 88 ?
res[res$RubricId==names(dups)[8], ]
# Different sections but provided same ID. Actual error. Drop 116.
res[res$RubricId==names(dups)[9], ]
# Drop 37
res[res$RubricId==names(dups)[10], ]
# Drop 93 ?
res[res$RubricId==names(dups)[11], ]
# Drop 92 ?
```
```{r}
id.drop <- c(2, 22, 41, 77, 71, 1, 83, 88, 116, 37, 93, 92)
res <- res %>% filter(!ID %in% id.drop)
```

And trim some variables and format.
```{r }
res <- res %>%
  mutate(across(c(ID, Email:Semester, Section:Course), factor) )
```

## Merge
Merge the survey data into the D2L.
```{r}
dim(df)
mdf <- df %>%
  left_join(res %>% select(RubricId, Instructor = Name, Course,
                           `Assessment Name`, Semester,
                           Section, Course), by="RubricId")
dim(mdf)
```

# Munge Data
Summary of the data:
```{r}
summary(mdf)
```

`113393` missing course ID, Semester, etc.

## Clean assessment and criterion names
Clean assessment names and criterion names (i.e. rubric rows). Start by standardizing upper/lower cases.
```{r clean-assessment}
mdf$`Assessment Name` <- str_to_title(mdf$`Assessment Name`)
mdf$Name <- str_to_title(str_remove(mdf$Name, '^"'))

pttrn.bus345 <- c("^Final Paper$" = "Ethics Final Paper")
pttrn.bus499 <-
  c("(^Final Company Paper$)|(^Company Profile$)|(^Final Company Profile$)|(^Course Profile$)" = "Company Profile (Final Paper)",
     "Simulation After-Action Report \\(Also Submitted To Gen Ed For Evidence Of Problem Solving\\)" = "Goventure Aar")
pttrn.eco201.a <- c("International Trade Signature Assignment" = "Trade Policy Paper")
pttrn.eco201.n <- c("^Arguments For Protection$"="Arguments For Protectionism",
                    "^Citations$"="Citations/References",
                    "^Structure$"="Structure/Clarity",
                    "^Winners/Losers$"="Winners And Losers",
                    "^Writing: Citations$"="Writing: Citations/References")
pttrn.eco202.a <- c("^Cross-Country Gdp Comparison Paper$" = "Gdp Comparison Paper")
pttrn.eco202.n <- 
  c("^Data Collection$" = "Part 1: Data Collection",
    "^Time-Series Graphs$" = "Part 1: Time Series Plots",
    "^Explain Variable Movements$" = "Part 2: Explain Variable Movements",
    "^Short-Run And Long-Run Perspectives$" = "Part 2: Short-Run And Long-Run Perspectives",
    "^Compare And Contrast$" = "Part 2: Compare And Contrast",
    "^Citations$" = "Writing: Citations",
    "^Grammar$" = "Writing: Grammar",
    "^Structure$" = "Writing: Structure")

pttrn.assess <- c(pttrn.bus345, pttrn.bus499, pttrn.eco202.a, pttrn.eco201.a)
pttrn.name <- c(pttrn.eco202.n, pttrn.eco201.n)

mdf <- mdf %>%
  mutate(Name = str_remove(Name, '^"'),
         `Assessment Name` = str_replace_all(`Assessment Name`, pttrn.assess),
         Name = str_replace_all(Name, pttrn.name))
```

## Standardize Achievment Levels
Standardize levels. As seen in Note 1, those levels can be inconsistent even with the same instructor (e.g. me) across semesters. *Extract* achievement levels from the mixture with other measures (i.e. attributes like major/minor, missing values) and some variants (e.g. 100%, 75%, etc.). Then standardize expressions.
```{r}
achievements1 <- c("Unsatisfactory", "Developing", "Basic", "Proficient", "Advanced")
achievements2 <- c("Unacceptable", "Rudimentary", "Fair", "Good", "Excellent")
names(achievements2) <- achievements1 # Named list as dictionary
pttrn <- paste(c(achievements1, achievements2), collapse = "|")

x <- levels(mdf$LevelAchieved)

mdf <- mdf %>% mutate(
  LevelAchieved.Original = LevelAchieved,
  LevelAchieved = str_extract(mdf$LevelAchieved, pttrn))
mdf$LevelAchieved <- str_replace_all(mdf$LevelAchieved, achievements2)
mdf$LevelAchieved <- ordered(mdf$LevelAchieved, levels = achievements2)

summary(mdf$LevelAchieved)
```

## New Variables
Add the achievement indicator variables for undergrad and grad levels.
```{r}
mdf <- mdf %>% mutate(
  Met.UND = case_when(
    is.na(LevelAchieved) ~ "Missing",
    LevelAchieved == "Excellent" | LevelAchieved == "Good" |
      LevelAchieved == "Fair" ~ "Met",
    LevelAchieved == "Rudimentary" | LevelAchieved == "Unacceptable" ~ "Not",
    TRUE ~ "Other"),
  Met.GRD = case_when(
    is.na(LevelAchieved) ~ "Missing",
    LevelAchieved == "Excellent" | LevelAchieved == "Good" ~ "Met",
    LevelAchieved == "Fair" | LevelAchieved == "Rudimentary" |
      LevelAchieved == "Unacceptable" ~ "Not",
    TRUE ~ "Other"),
  Online = grepl("GW", Section),
  Met.UND.bin = Met.UND == "Met",
  Met.GRD.bin = Met.GRD == "Met"
  )
table(mdf$LevelAchieved, mdf$Met.UND, useNA = "ifany")
```

# Investigate

## Macro Measures
Prevalence of Achievements will be used for internal assessments in ACBSP document. Let's just compute them all! Course-level (i.e. aggregate over sections and instructors) shares of students who achieved a passing level grades for each rubric row.

```{r}
tbl <- mdf %>% filter(str_detect(Name, "Major|Minor", negate = TRUE)) %>%
  group_by(Course, `Assessment Name`, Name) %>%
  summarise(across(ends_with(".bin"), mean))
knitr::kable(tbl, digits = 2)
```

```{r, fig.width=9, fig.height=14}
ggplot(tbl %>% filter(str_detect(Course, "BUS"))) +
  geom_col(aes(str_sub(Name, 1, 30), Met.UND.bin)) + coord_flip() + 
#  facet_wrap(Course ~ `Assessment Name`, scale = "free")
  facet_wrap(vars(Course, `Assessment Name`), scales = "free", ncol=2)
```
```{r, fig.width=9, fig.height=14}
ggplot(tbl %>% filter(str_detect(Course, "ECO"))) +
  geom_col(aes(str_sub(Name, 1, 35), Met.UND.bin)) + coord_flip() + 
  facet_wrap(vars(Course, `Assessment Name`), scales = "free", ncol=2)
```

```{r, fig.width=9, fig.height=14}
ggplot(tbl %>% filter(str_detect(Course, "HRM"))) +
  geom_col(aes(str_sub(Name, 1, 20), Met.UND.bin)) + coord_flip() + 
  facet_wrap(vars(Course, `Assessment Name`), scales = "free", ncol=2)
```
```{r, fig.width=9, fig.height=14}
ggplot(tbl %>% filter(str_detect(Course, "MGT"))) +
  geom_col(aes(str_sub(Name, 1, 20), Met.UND.bin)) + coord_flip() + 
  facet_wrap(vars(Course, `Assessment Name`), scales = "free", ncol=2)
```

```{r, fig.width=9, fig.height=14}
ggplot(tbl %>% filter(str_detect(Course, "MKT"))) +
  geom_col(aes(str_sub(Name, 1, 20), Met.UND.bin)) + coord_flip() + 
  facet_wrap(vars(Course, `Assessment Name`), scales = "free", ncol=2)
```

### Some are too low?
Some numbers look strange.
```{r}
table(mdf$Met.GRD, mdf$LevelAchieved, useNA = "ifany")
```

```{r}
table(mdf$Met.GRD, mdf$Met.GRD.bin, useNA = "ifany")
```

```{r}
x <- mdf %>% filter(str_detect(Name, "Major|Minor", negate = TRUE)) 
table(x$Met.GRD, x$Met.GRD.bin, useNA = "ifany")
```

Okay, missing values are counted as "Not Met".

```{r}
mdf[mdf$Met.GRD == "Missing", "Met.GRD.bin"] <- NA
mdf[mdf$Met.UND == "Missing", "Met.UND.bin"] <- NA

table(mdf$Met.GRD, mdf$Met.GRD.bin, useNA = "ifany")
```


```{r, fig.width=9, fig.height=14}
tbl <- mdf %>% filter(str_detect(Name, "Major|Minor", negate = TRUE)) %>%
  group_by(Course, `Assessment Name`, Name) %>%
  summarise(across(ends_with(".bin"), mean, na.rm = TRUE))

p_met_und <- function(prg) {
  ggplot(tbl %>% filter(str_detect(Course, prg))) +
  geom_col(aes(str_sub(Name, 1, 20), Met.UND.bin)) + coord_flip() + 
  facet_wrap(vars(Course, `Assessment Name`), scales = "free", ncol=2) +
  geom_hline(yintercept = 0.70, color = "red")
}
```
```{r, fig.width=9, fig.height=14}
p_met_und("HRM")
```

?

```{r}
x <- mdf %>% filter(Course == "HRM 400")
summary(x)
```
```{r}
#x %>% filter(Name =="Organizational Types") %>% group_by(LevelAchieved) %>% summarize(mean(Score))
ggplot(x %>% filter(Name =="Organizational Types")) +
  geom_bar(aes(LevelAchieved))
```
So... it was actually bad?

Make sure the conversion was done properly.
```{r}
x <- droplevels(x)
table(x$LevelAchieved, x$LevelAchieved.Original)
```


### Some are too high?
Because of the truncation, some are merged together. > Fixed manually for now.

## Macro Measure Again

```{r}
#programs <- levels(factor(str_sub(mdf$Course, 1, 3)))

tbl <- mdf %>% filter(str_detect(Name, "Major|Minor", negate = TRUE)) %>%
  group_by(Course, `Assessment Name`, Name) %>%
  summarise(across(ends_with(".bin"), mean, na.rm = TRUE))

p_met_und <- function(prg) {
  ggplot(tbl %>% filter(str_detect(Course, prg))) +
  geom_col(aes(str_wrap(Name, 20), Met.UND.bin)) + coord_flip() + 
  facet_wrap(vars(Course, `Assessment Name`), scales = "free", ncol=2) +
  geom_hline(yintercept = 0.70, color = "red")
}
```
```{r, fig.width=9, fig.height=14}
p_met_und("BUS")
```
```{r, fig.width=9, fig.height=14}
p_met_und("ECO")
```
```{r, fig.width=9, fig.height=14}
p_met_und("HRM")
```
```{r, fig.width=9, fig.height=14}
p_met_und("MGT")
```
```{r, fig.width=9, fig.height=14}
p_met_und("MKT")
```

There are more things to address though. Pause here.